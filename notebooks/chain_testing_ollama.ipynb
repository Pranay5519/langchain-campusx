{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88fdc273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel , RunnableBranch , RunnableLambda\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# -------------------------\n",
    "# 1Ô∏è‚É£ Pydantic Schema\n",
    "# -------------------------\n",
    "class Feedback(BaseModel):\n",
    "    sentiment: Literal['positive', 'negative'] = Field(\n",
    "        description=\"Give the sentiment of the Feedback\"\n",
    "    )\n",
    "llm = ChatOllama(\n",
    "    model=\"qwen3:latest\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d81f1357",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"This is a terrible phone\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef5e1b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentiment of the following feedback text into positive or negative:\n",
      "This is a terrible phone\n",
      "\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"sentiment\": {\"description\": \"Give the sentiment of the Feedback\", \"enum\": [\"positive\", \"negative\"], \"title\": \"Sentiment\", \"type\": \"string\"}}, \"required\": [\"sentiment\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "pydantic_feedback_parser = PydanticOutputParser(pydantic_object=Feedback)\n",
    "prompt1 = PromptTemplate(\n",
    "    template=\"Classify the sentiment of the following feedback text into positive or negative:\\n\"\n",
    "             \"{feedback}\\n\\n{format_instructions}\",\n",
    "    input_variables=['feedback'],\n",
    "    partial_variables={'format_instructions': pydantic_feedback_parser.get_format_instructions()}\n",
    ")\n",
    "print(prompt1.format(feedback=user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc7e3f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt1 | llm | pydantic_feedback_parser\n",
    "\n",
    "classifier_output = chain.invoke({\"feedback\": user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d99538a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feedback(sentiment='negative')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eedb7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = PromptTemplate(\n",
    "    template='Write an appropriate response to this positive feedback \\n {feedback}',\n",
    "    input_variables=['feedback']\n",
    ")\n",
    "\n",
    "prompt3 = PromptTemplate(\n",
    "    template='Write an appropriate response to this negative feedback \\n {feedback}',\n",
    "    input_variables=['feedback'] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8cbad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch_chain = RunnableBranch(\n",
    "    (lambda x:x.sentiment == 'positive', prompt2 | llm | StrOutputParser()),\n",
    "    (lambda x:x.sentiment == 'negative', prompt3 | llm | StrOutputParser()),\n",
    "    RunnableLambda(lambda x: \"could not find sentiment\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6bf64b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"response\": \"We\\'re sorry to hear that you\\'re experiencing issues with your order. We value your feedback and apologize for the inconvenience caused. Could you please share more details about the problem you encountered? Our team is here to help resolve this promptly, whether it\\'s a refund, replacement, or other solution. Your satisfaction is important to us, and we appreciate the opportunity to improve. Please let us know how we can assist further!\"\\n}'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "branch_chain.invoke(classifier_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "290b29e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Response:**  \n",
      "\"Thank you so much for your kind words! I'm really glad to hear that. How are you doing? If there's anything else I can assist you with, feel free to let me know! üòä\"  \n",
      "\n",
      "This response acknowledges the feedback warmly, expresses gratitude, and opens the door for further engagement. It maintains a friendly and approachable tone.\n"
     ]
    }
   ],
   "source": [
    "chain = chain | branch_chain \n",
    "result = chain.invoke({'feedback': 'This is a beautiful phone'})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc520fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "**---------\n",
      "Response---------\n",
      ":**---------\n",
      "  \n",
      "---------\n",
      "\"---------\n",
      "Thank---------\n",
      " you---------\n",
      " so---------\n",
      " much---------\n",
      " for---------\n",
      " your---------\n",
      " kind---------\n",
      " words---------\n",
      "!---------\n",
      " I---------\n",
      "'m---------\n",
      " really---------\n",
      " glad---------\n",
      " to---------\n",
      " hear---------\n",
      " that---------\n",
      ".---------\n",
      " How---------\n",
      " are---------\n",
      " you---------\n",
      " doing---------\n",
      "?---------\n",
      " If---------\n",
      " there---------\n",
      "'s---------\n",
      " anything---------\n",
      " else---------\n",
      " I---------\n",
      " can---------\n",
      " assist---------\n",
      " you---------\n",
      " with---------\n",
      ",---------\n",
      " feel---------\n",
      " free---------\n",
      " to---------\n",
      " let---------\n",
      " me---------\n",
      " know---------\n",
      "!---------\n",
      " üòä---------\n",
      "\"---------\n",
      "  \n",
      "\n",
      "---------\n",
      "This---------\n",
      " response---------\n",
      " acknowledges---------\n",
      " the---------\n",
      " feedback---------\n",
      " warmly---------\n",
      ",---------\n",
      " expresses---------\n",
      " gratitude---------\n",
      ",---------\n",
      " and---------\n",
      " opens---------\n",
      " the---------\n",
      " door---------\n",
      " for---------\n",
      " further---------\n",
      " engagement---------\n",
      ".---------\n",
      " It---------\n",
      " maintains---------\n",
      " a---------\n",
      " friendly---------\n",
      " and---------\n",
      " approach---------\n",
      "able---------\n",
      " tone---------\n",
      ".---------\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "for chunk in chain.stream({'feedback': 'This is a beautiful phone'}):\n",
    "    #print(\"---------\")\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23d1c3a",
   "metadata": {},
   "source": [
    "* qwen3:latest model is generating Pydantic strOutput \n",
    "* lambda:3.2 latest model is sometimes generates the pydantic output and sometimes not\n",
    "    1) because is not a thinking model\n",
    "    2) It does not even support Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7787cedd",
   "metadata": {},
   "source": [
    "# manually running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32531f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_text = \"This is a terrible phone\"\n",
    "str_output_parser = StrOutputParser()\n",
    "# Step 2: Branch manually\n",
    "if classifier_output.sentiment == \"positive\":\n",
    "    formatted_response_prompt = prompt2.format(feedback=feedback_text)\n",
    "elif classifier_output.sentiment == \"negative\":\n",
    "    formatted_response_prompt = prompt3.format(feedback=feedback_text)\n",
    "else:\n",
    "    print(\"Could not find sentiment\")\n",
    "    exit()\n",
    "\n",
    "# Step 3: Generate response\n",
    "response_raw = llm.invoke(formatted_response_prompt)\n",
    "final_response = str_output_parser.invoke(response_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fe675bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"response\": \"I'm sorry to hear that you're experiencing issues with your phone. I completely understand how frustrating that must be. Could you please let me know what specific problems you're encountering? Whether it's performance, battery life, or something else, I'd be happy to help you troubleshoot or find a solution. Your satisfaction is important, and I'm here to assist you in any way I can. Feel free to reach out if there's anything else I can do to resolve this.\"}\n"
     ]
    }
   ],
   "source": [
    "print(final_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
